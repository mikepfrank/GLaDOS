
from	os	import path

from	infrastructure.decorators	import	singleton

				#-------------------------------------------------------------
				# The logmaster module defines our logging framework; we
				# import specific definitions we need from it.	(This is a
				# little cleaner stylistically than "from ... import *".)

from 	infrastructure.logmaster 	import getComponentLogger

	# Go ahead and create or access the logger for this module.

global _component, _logger		# Software component name, logger for component.

_component = path.basename(path.dirname(__file__))				# Our package name.
_logger = getComponentLogger(_component)						# Create the component logger.

from	entities.entity				import	(
		AI_Entity_,			# Abstract base class for AI entities.
		Cognitive_System	# The AI's cognitive subsystem specifically.
	)

from	config.configuration		import	TheAIPersonaConfig

from	supervisor.action			import	(
		Action_, SpeechAction_, CommandAction_, ActionChannel_,
		ActionBySystem_, AnnouncementAction_, ActionByHuman_
	)

# Forwards
class	ActionByAI_:					pass
class	AI_Speech_Action:				pass
class	CommandByAI_:					pass
class	The_AI_Cognosphere_Channel:		pass

#---------------------------------------------------------------------------------------
# The following classes are for various types of actions that could be taken by the AI.


class ActionByAI_(Action_):
	def __init__(thisAiAction, 
			description:str="A generic action was taken by the AI.",
				# REQUIRED. A description string. SUBCLASSES SHOULD OVERRIDE THIS VALUE.
			conceiver:AI_Entity_=None,		# The AI entity that conceived of taking this action.
			importance:int=0,			# Importance level that we declare this action to have. Default 0.
		):
		
			# Remember the declared importance level of this AI action.
		thisAiAction._importance = importance

			# Set the conceiver implicitly.
		if conceiver is None:
			conceiver = Cognitive_System()
			# We ascribe AI actions to the AI's cognitive system unless they're more specifically
			# attributed to its persona, API, or other aspect of the AI.

		super(ActionByAI_, thisAiAction).__init__(description=description, conceiver=conceiver)


class FallAsleepAction: pass
class FallAsleepAction(ActionByAI_):

	"""Class for the action of the AI falling asleep."""

	selfExecuting = True

	def __init__(newFallAsleepAction:FallAsleepAction, thread, importance:int=7):
		faAct = newFallAsleepAction
		faAct._thread = thread
		personaName = thread.personaName
		description = f"{personaName} is falling asleep."
		super(FallAsleepAction, faAct).__init__(description, importance)

	def executionDetails(newFallAsleepAction:FallAsleepAction):
		thread.executeFallAsleep()

class WakeUpAction: pass
class WakeUpAction(ActionByAI_):

	"""Class for the action of the AI waking up (spontaneously)."""

	selfExecuting = True

	def __init__(newWakeUpAction:WakeUpAction, thread, importance:int=7):
		waAct = newWakeUpAction
		waAct._thread = thread
		personaName = thread.personaName
		description = f"{personaName} is waking up."
		super(WakeUpAction, waAct).__init__(description, importance)

	def executionDetails(newWakeUpAction:WakeUpAction):
		thread.executeWakeUp()




class _AiAnnouncementAction: pass
class _AiAnnouncementAction(ActionByAI_, AnnouncementAction_):

	"""Class for system announcements generated by the AI."""

	def __init__(thisAnnouncementAction:_AiAnnouncementAction,
			announcementText:str="Generic announcement.",
			importance:int=3,	# Default level for announcements.
		):

		annAct = thisAnnouncementAction

		description=f"The AI's cognitive system announces: \"{announcementText}\""

		_logger.debug("_AiAnnouncementAction.__init__(): Initializing "
					  f"announcement action. Description: '{description}'")

		super(_AiAnnouncementAction, annAct).__init__(
			description, importance=importance)
	

#	AnnounceFieldExistsAction(ActionByAI) -
#
#		This is a class of action that is taken by the AI as soon as its 
#		receptive field has been created, and is ready for entities outside
#		of itself to begin writing information into it.  Like all actions, 
#		as soon as it gets created and initiated, it gets automatically 
#		processed by the supervisor's ActionProcessor.  This responds 
#		appropriately, for example, by telling the application system that 
#		its windows that want to auto-open can now open themselves on the 
#		field.

class AnnounceFieldExistsAction: pass
class AnnounceFieldExistsAction(_AiAnnouncementAction):
	
	"""Class for the cognitive system to announce that the receptive field exists."""

	def __init__(thisAction:AnnounceFieldExistsAction,
			announcementText:str="The AI's receptive field is ready to receive data.",
			importance:int=8,	# Receptive field existence is very important.
		):

		_logger.debug("AnnounceFieldExistsAction.__init__(): Initializing field-existence "
					  f"announcement action. Announcement text is: '{announcementText}'")

		super(AnnounceFieldExistsAction, thisAction).__init__(
			announcementText, importance)


class AnnounceEnergyAction: pass
class AnnounceEnergyAction(_AiAnnouncementAction):
	
	"""Class for the cognitive system to announce the AI's energy level."""

	def __init__(thisAction:AnnounceEnergyAction,
			announcementText:str="The AI's energy level is low.",
			importance:int=3,	# Low energy message is somewhat important
		):

		_logger.debug("AnnounceEnergyAction.__init__(): Initializing energy "
					  f"announcement action. Announcement text is: '{announcementText}'")

		super(AnnounceEnergyAction, thisAction).__init__(
			announcementText, importance)


class AI_Speech_Action(SpeechAction_, ActionByAI_):

	"""Class for actions by the AI that consist of it producing some text output.
		At the moment, all actions taken by the AI start out as this type of action,
		and then other types of actions are derived from them as they are 
		interpreted by the system (in particular, the command interface).
	
		AI_Speech_Action instances get created in the main loop of the cognitive
		system upon receiving a completion from the AI; they are then automatically
		initiated. Credit for their conception goes to the persona (annotated as 
		running on the language model); credit for their initiation goes to the 
		cognitive system (on behalf of the persona); credit for their execution 
		goes to the cognitive system as well I guess.  
		
		For resulting command actions, we can credit conception to the AI, initiation
		to the Supervisor, and execution to whatever subsystem/app implements them.
		They can also link back to the speech action they were derived from.
	"""
		
	def __init__(this,
			aiTextOut:str=None,		# Text output by the AI.
			theAI:AI_Entity_=None,	# The AI entity that conceived of taking this action.
		):
		
			# Get a string denoting the AI.
		this._aiStr = aiStr = str(theAI)
		
			# Store the AI's output text for later reference.
		this._aiTextOut = aiTextOut
		
			# Compose an action description, pretty generic but that's fine for now. 
		description = f"AI {aiStr} generated the text: [{aiTextOut}]."
			# (Later on, if this speech action ends up getting parsed as a command string,
			# then this action may end up also invoking a command action of some sort.)
			
			# Dispatch to next class in inheritance chain to finish initialization.
		super(AI_Speech_Action, this).__init__(aiTextOut, description, theAI)
			# Note dispatch order goes first to SpeechAction_, then to ActionByAI_.

	# Note to self: Should we go ahead and add AI speech actions to the cognitive stream 
	# immediately upon conception? Or wait until the command (if any) is interpreted?
	# I'm thinking yes, we should go ahead and add them at execution time, and the 
	# command (if any) should be treated as a second action that is consequent on
	# ("invoked by") the first action. Use ".interpretedAs" and ".triggeredBy" members
	# as appropriate.

class CommandByAI_(CommandAction_, ActionByAI_):
	# Note the superclass resolution order here is important: CommandAction_
	# parses out the cmdLine and cmdType arguments, then we pass the rest of
	# the arguments on to ActionByAI_ for further processing.
	pass


# Consider moving this to the mind package since it depends on configuration
# parameters for the AI persona.
@singleton
class The_AI_Cognosphere_Channel(ActionChannel_):

	"""The action system creates this specific action channel which is for 
		reporting actions that we consider eligible for entering into the
		AI's sphere of awareness.  Such actions include:
		
			(1) All actions that were conceived/initiated by the AI 
				itself.
			
			(2) All actions that were conceived/initiated by a human
				user who has logged into GLaDOS to interact with the AI.
			
			(3) All high-importance system actions, which the AI might
				need to be aware of.  The threshold importance level can
				be configured in the system/AI configuration."""

	channelName = "AICC (AI Cognosphere Channel)"

	def willReport(thisChannel, status:str, action:Action_):
		
			# At present, we report all status updates for actions, including
			# 'conceived', 'initiated', 'executing', and 'completed'.  However,
			# the individual subscriber can choose to ignore most of these.
			
		# At first we ignored non-complete actions, but this is commented out.
		#if status != 'completed': return False
		
			# Next, see if this is an action by the AI itself.  An easy way
			# to check this is to see if this action is an ActionByAI_. 
			# (Instance of this class, or a subclass derived from it.)  A 
			# more sophisticated way would be to actually look at the entity
			# specified in the ._conceivedBy and/or ._initiatedBy members.
			# However, we'll just use the simple method for now.
			#
			# NOTE: We make an exception here for the Field Exists action,
			# since it seems to confuse Gladys.
			
		isAIAction = isinstance(action, ActionByAI_)
		if isAIAction:

			### Don't report the field-existence announcement.
			##if isinstance(action, AnnounceFieldExistsAction):
			##	return False

			return True
		
		# Human actions include those taken by the Operator on
		# the system console, and a human logged in through a
		# local or remote terminal.  Report those to the AI.

		isHumanAction = isinstance(action, ActionByHuman_)
		if isHumanAction:	return True

		# Next, check to see if this is a system-initiated action.
		# Anything else, we don't report yet.  But system actions
		# will be reported as long as they're over threshold.
			
		isSystemAction = isinstance(action, ActionBySystem_)
		if not isSystemAction:	return False
		
			# Get its importance, and our threshold level.
		
		importance = action._importance
		threshold = TheAIPersonaConfig().sysNotifyThresh
		
			# For system actions, we'll only broadcast them into the AI's cognitive
			# sphere if they're at or above the current importance-level threshold.
		return importance >= threshold
		
	
